run_id,embedding_model,embedding_size,retrieval_k,prompt_strategy,llm_model,f1_score,exact_match,faithfulness,answer_relevancy,context_recall,context_precision,factual_correctness,enhanced
1,all-MiniLM-L6-v2,384,3,Instruction,gemini-2.5-flash-lite,21.9453,1.7034,0.9308,0.8532,0.6088,0.8221,0.1549,FALSE
2,all-MiniLM-L6-v2,384,5,Instruction,gemini-2.5-flash-lite,22.7411,1.634,0.9244,0.8493,0.6129,0.8137,0.1585,FALSE
3,all-MiniLM-L6-v3,384,5,CoT,gemini-2.5-flash-lite,0.7852,0,,,,,,
4,all-MiniLM-L6-v4,384,5,Persona,gemini-2.5-flash-lite,3.9723,0,,,,,,
5,all-MiniLM-L6-v3,384,10,Instruction,gemini-2.5-flash-lite,22.5315,1.5882,0.9015,0.8411,0.6314,0.7852,0.1571,FALSE
6,all-mpnet-base-v2,768,3,Instruction,gemini-2.5-flash-lite,23.8541,2.1507,0.9355,0.8812,0.6533,0.8468,0.1724,FALSE
7,all-mpnet-base-v3,768,5,Instruction,gemini-2.5-flash-lite,24.5218,2.3196,0.941,0.8794,0.6805,0.8291,0.1803,FALSE
8,all-mpnet-base-v4,768,10,Instruction,gemini-2.5-flash-lite,24.1893,2.2413,0.9288,0.8659,0.7149,0.7914,0.1788,FALSE
9,all-MiniLM-L6-v1,384,3,Instruction,gemini-2.5-flash-lite,22.8519,1.455,0.9415,0.834,0.6251,0.8813,0.1594,TRUE
10,all-MiniLM-L6-v2,384,5,Instruction,gemini-2.5-flash-lite,23.2606,1.3072,0.9322,0.8108,0.6493,0.8648,0.1616,TRUE
11,all-MiniLM-L6-v3,384,10,Instruction,gemini-2.5-flash-lite,22.9588,1.2591,0.9198,0.8055,0.6718,0.8302,0.1601,TRUE